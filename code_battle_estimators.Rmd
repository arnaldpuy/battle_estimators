---
title: "The battle of total-order sensitivity estimators"
author: "Arnald Puy, Samuele Lo Piano, Andrea Saltelli and William Becker"
header-includes:
  - \usepackage[font=footnotesize]{caption}
  - \usepackage{dirtytalk}
  - \usepackage{booktabs}
  - \usepackage{tabulary}
  - \usepackage{enumitem}
  - \usepackage{lmodern}
  - \usepackage[T1]{fontenc}
output:
  pdf_document:
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_depth: 2
    keep_tex: true
  word_document:
    toc: no
    toc_depth: '2'
  html_document:
    keep_md: true
link-citations: yes
fontsize: 11pt
bibliography: /Users/arnald/Documents/bibtex/ERC-sensitivity.bib

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

```{r preliminary steps, results="hide", message=FALSE, warning=FALSE}

# PRELIMINARY FUNCTIONS -------------------------------------------------------

# Function to read in all required packages in one go:
loadPackages <- function(x) {
  for(i in x) {
    if(!require(i, character.only = TRUE)) {
      install.packages(i, dependencies = TRUE)
      library(i, character.only = TRUE)
    }
  }
}

# Install development version of sensobol
remotes::install_github("arnaldpuy/sensobol")

# Load the packages
loadPackages(c("Rcpp", "RcppArmadillo", "tidyverse", "parallel", "foreach", 
               "doParallel", "Rfast", "data.table", "scales", "cowplot", 
               "benchmarkme", "logitnorm", "sensobol"))

# Create custom theme
theme_AP <- function() {
  theme_bw() +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          legend.background = element_rect(fill = "transparent",
                                           color = NA),
          legend.key = element_rect(fill = "transparent",
                                    color = NA))
}

# Set checkpoint

dir.create(".checkpoint")
library("checkpoint")

checkpoint("2020-01-23", 
           R.version ="3.6.1", 
           checkpointLocation = getwd())
```

\newpage 

## Savage scores

The following code snippet allows to compute Savage scores [@Iman1987], which read as 
\begin{equation}
SS_i=\sum_{j=1}^{N}\frac{1}{j}
\label{eq:savage}
\end{equation}

Savage scores will be used as a measure of performance to check how well each estimator identifies the true ranks of the most important model inputs.

```{r savage_scores, cache=TRUE}

# SAVAGE SCORES --------------------------------------------------------------------

savage_scores <- function(x) {
  true.ranks <- rank(-x)
  p <- sort(1 / true.ranks)
  mat <- matrix(rep(p, length(p)), nrow = length(p), byrow = TRUE)
  mat[upper.tri(mat)] <- 0
  out <- sort(rowSums(mat), decreasing = TRUE)[true.ranks]
  return(out)
}
```

## Sobol' indices

We define here all the $T_i$ estimators we will analyze in our study: @Jansen1999, @Janon2014a, @Homma1996, @Azzini2019 and @Sobol2008. We then prove that the code works by computing and plotting the $T_i$ indices of three well-known test functions: the @Ishigami1990, the @Sobol1993 's G and the @Morris1991 functions.

```{r ti_indices, cache=TRUE, dependson="savage_scores"}

# COMPUTATION OF SOBOL' Ti INDICES -------------------------------------------------

sobol_Ti <- function(d, N, params, total) {
  m <- matrix(d, nrow = N)
  k <- length(params)
  if(!total == "azzini") {
    Y_A <- m[, 1]
    Y_AB <- m[, -1]
    f0 <- (1 / length(Y_A)) * sum(Y_A)
    VY <- 1 / length(Y_A) * sum((Y_A - f0) ^ 2)
     # VY <- 1 / length(Y_A) * (sum(Y_A ^ 2) - 
    # (1 / N * sum(Y_A ^ 2))) ((Variance used by Becker))
  }
  if(total == "jansen") {
    Ti <- (1 / (2 * N) * Rfast::colsums((Y_A - Y_AB) ^ 2)) / VY
  } else if(total == "homma") {
    Ti <- (VY - (1 / N) * Rfast::colsums(Y_A * Y_AB) + f0 ^ 2) / VY
  } else if(total == "sobol") {
    Ti <- ((1 / N) * Rfast::colsums(Y_A * (Y_A - Y_AB))) / VY
  } else if(total == "monod") {
    Ti <- 1 - (1 / N * Rfast::colsums(Y_A * Y_AB) - 
                  (1/ N * Rfast::colsums((Y_A + Y_AB) / 2)) ^ 2) / 
      (1 / N * Rfast::colsums((Y_A ^ 2 + Y_AB ^ 2) / 2) - 
         (1/ N * Rfast::colsums((Y_A + Y_AB) / 2)) ^ 2)
  }
  if(total == "azzini") {
    Y_A <- m[, 1]
    Y_B <- m[, 2]
    Y_AB <- m[, 3:(3 + k - 1)]
    Y_BA <- m[, (ncol(m) - k + 1):ncol(m)]
    Ti <- 1 - abs(Rfast::colsums((Y_A - Y_BA) * (Y_B - Y_AB)) / 
                     (1 / 2 * Rfast::colsums((Y_A - Y_B) ^ 2 + (Y_AB - Y_BA) ^ 2)))
  } 
  output <- data.table(Ti)
  output[, `:=`(parameters = paste("X", 1:k, sep = ""))]
  return(output)
}
```

```{r check_ti, cache=TRUE, dependson="ti_indices"}

# CHECK THAT ALL TI ESTIMATORS WORK ------------------------------------------------

# Settings
estimators <- c("jansen", "sobol", "homma", "azzini", "monod")
test_functions <- c("Ishigami", "Sobol'G", "Morris")
N <- 2^9

# Run model
ind <- Y <- mt <- list() 
for(i in estimators) {
  for(j in test_functions) {
    if(!i == "azzini") {
      matrices <- c("A", "AB")
    } else {
      matrices <- c("A", "B", "AB", "BA")
    }
    if(j == "Ishigami") {
      k <- 3
      modelRun <- sensobol::ishigami_Fun
    } else if(j == "Sobol'G") {
      k <- 8
      modelRun <- sensobol::sobol_Fun
    } else if(j == "Morris") {
      k <- 20
      modelRun <- sensitivity::morris.fun
    }
    mt[[i]][[j]] <- sobol_matrices(N = N, params = paste("X", 1:k, sep = ""), matrices = matrices)
    Y[[i]][[j]] <- modelRun(mt[[i]][[j]])
    ind[[i]][[j]] <- sobol_Ti(d = Y[[i]][[j]], params = paste("X", 1:k, sep = ""), 
                              N = N, total = i)
  }
}
```

```{r plot_prove, cache=TRUE, dependson="check_ti", dev="tikz", fig.height=3, fig.width=6.5}

# PLOT SENSITIVITY INDICES ---------------------------------------------------------

lapply(ind, function(x) rbindlist(x, idcol = "Function")) %>%
  rbindlist(., idcol = "estimator") %>%
  .[, parameters:= factor(parameters, levels = paste("X", 1:20, sep = ""))] %>%
  .[, Function:= factor(Function, levels = test_functions)] %>%
  ggplot(., aes(parameters, Ti, fill = estimator)) +
  geom_bar(stat = "identity", 
           position = position_dodge(0.7), 
           color = "black") +
  facet_grid(~Function, 
             scales = "free_x", 
             space = "free_x") +
  scale_fill_discrete(name = expression(paste("Sobol' ", T[italic(i)])),
                      labels = c("Azzini", "Homma", "Jansen", 
                                 "Monod", "Sobol")) +
  labs(x = "",
       y = expression(T[italic(i)])) +
  theme_AP() + 
  theme(axis.text.x = element_text(size = 6.5), 
        legend.position = "top")
```

# The metafunction

We first start by creating a list with the ten univariate functions that the metafunction will include, and plot them.

```{r functions_metafunction, cache=TRUE}

# CREATE METAFUNCTION --------------------------------------------------------------

function_list <- list(
  Linear = function(x) x,
  Quadratic = function(x) x ^ 2,
  Cubic = function(x) x ^ 3,
  Exponential = function(x) exp(1) ^ x / (exp(1) - 1),
  Periodic = function(x) sin(2 * pi * x) / 2,
  Discontinuous = function(x) ifelse(x > 0.5, 1, 0),
  Non.monotonic = function(x) 4 * (x - 0.5) ^ 2,
  Inverse = function(x) (10 - 1 / 1.1) ^ -1 * (x + 0.1) ^ - 1, 
  No.effect = function(x) x * 0, 
  Trigonometric = function(x) cos(x)
)
```

```{r plot_functions_metafunction, cache=TRUE, dependson="functions_metafunction", dev = "tikz", fig.height=2.7, fig.width=4.6, fig.cap="Functions used in the metafunction of @Becker2019."}

# PLOT METAFUNCTION ----------------------------------------------------------------

a <- ggplot(data.frame(x = runif(100)), aes(x)) +
  map(1:length(function_list), function(nn) {
    stat_function(fun = function_list[[nn]], 
                  geom = "line", 
                  aes_(color = factor(names(function_list[nn])), 
                       linetype = factor(names(function_list[nn]))))
  }) + 
  labs(color= "Function", linetype = "Function", 
       x = expression(italic(x)), 
       y = expression(italic(y))) +
  theme_AP() + 
  theme(legend.position = "right")

a
```

```{r function_distributions, cache=TRUE}

# CREATE FUNCTION FOR RANDOM DISTRIBUTIONS -----------------------------------------

sample_distributions <- list(
  "uniform" = function(x) x,
  "normal" = function(x) qnorm(x, 0.5, 0.2),
  "beta" = function(x) qbeta(x, 8, 2),
  "beta2" = function(x) qbeta(x, 2, 8),
  "beta3" = function(x) qbeta(x, 2, 0.5),
  "beta4" = function(x) qbeta(x, 0.5, 2),
  "logitnormal" = function(x) qlogitnorm(x, 0, 3.16)
  # Logit-normal, Bates too?
)

random_distributions <- function(X, phi) {
  names_ff <- names(sample_distributions)
  if(!phi == length(names_ff) + 1) {
    out <- sample_distributions[[names_ff[phi]]](X)
  } else {
    temp <- sample(names_ff, ncol(X), replace = TRUE)
    out <- sapply(seq_along(temp), function(x) sample_distributions[[temp[x]]](X[, x]))
  }
  return(out)
}
```

```{r plot_function_distributions, cache=TRUE, dependson=c("function_distributions", "function_distributions"), dev = "tikz", fig.height=2.7, fig.width=4.6, fig.cap="Distributions used in the metafunction of @Becker2019."}

# PLOT DISTRIBUTIONS ---------------------------------------------------------------

names_ff <- names(sample_distributions)
prove <- randtoolbox::sobol(n = 1000, dim = length(names_ff))

out <- data.table(sapply(seq_along(names_ff), function(x) 
  sample_distributions[[names_ff[x]]](prove[, x])))

b <- data.table::melt(out) %>%
  ggplot(., aes(value, group = variable, colour = variable)) + 
  geom_density() + 
  scale_color_discrete(labels = c("$U(0, 1)$", 
                                  "$\\mathcal{N}(0.5, 0.2)$", 
                                  "$Beta(8, 2)$", 
                                  "$Beta(2, 8)$", 
                                  "$Beta(2, 0.5)$", 
                                  "$Beta(0.5, 2)$", 
                                  "$Logitnormal(0, 3.16)$"), 
                       name = "") +
  labs(x = expression(italic(x)), 
       y = "Density") +
  theme_AP() 

b
```

```{r metafunctions_distributions, cache=TRUE, dependson=c("functions_metafunction", "function_distributions", "plot_functions_metafunction", "plot_function_distributions"), dev="tikz", fig.height=5, fig.width=4.6}

# MERGE METAFUNCTION PLOT AND DISTRIBUTIONS PLOT -----------------------------------

plot_grid(a, b, ncol = 1, labels = "auto", align = "hv")
```

We next show how the metafunction works:

```{r show_metafunction, cache=TRUE, dependson=c("metafunction", "function_distributions", "sobol_indices_f", "sobol_matrices_functions")}

# EXEMPLIFY THE METAFUNCTION WITH AN EXAMPLE ---------------------------------------

N <- 5000 # Sample size
R <- 100 # Number of bootstrap replications
k <- 55 # Number of model inputs
k_2 <- 0.5 # Fraction of active pairwise interactions
k_3 <- 0.3 # Fraction of active three-wise interactions
epsilon <- 5 # to reproduce the results
params <- paste("X", 1:k, sep = "")
A <- sobol_matrices(N = N, params = params)

# Compute
Y <- metafunction(data = A, k_2 = k_2, k_3 = k_3, epsilon = epsilon)
ind <- sobol_indices(Y = Y, N = N, params = params, R = R, boot = TRUE)
```

# The model

This section sets the ground for the battle of the estimators.

## Settings

We first define the settings of the analysis, including the sample size of the base sample matrix. This sample matrix will initially have two columns: $k$ (which will define the dimensionality of the metafunction) and $C$ (which will define the total cost or the total number of runs of the metafunction). `N.high` defines the size of the sample matrix that will be used to compute the "true" ranks for each run of the metafunction.

```{r settings, cache=TRUE}

# DEFINE SETTINGS ------------------------------------------------------------------

N <- 2 ^ 11 # Sample size of sample matrix
R <- 500 # Number of bootstrap replicas
n_cores <- ceiling(detectCores() * 0.5)
order <- "first"
params <- c("k", "N_t", "k_2", "k_3", "epsilon", "phi", "delta") 
N.high <- 2 ^ 11 # Maximum sample size of the large sample matrix
```

## Sample matrix

Here we create the sample matrix using Sobol' quasi-random number sequences, and transform each column to its appropriate distribution: the first column will define the dimensionality $k$ of the metafunction, and we will describe it as $k\sim \mathcal{U}(3,200)$. The second column will define the total cost $C$ of the analysis and will be described as $k\sim \mathcal{U}(10,2000)$. Finally, we create two extra columns that will define the initial sample size of the matrix needed to compute the all estimators but @Azzini2019 (`N.all`), and @Azzini2019 (`N.azzini`), given the value of $C$ and $k$ in each row of the sample matrix.

```{r sample_matrix, cache=TRUE, dependson="settings"}

# CREATE SAMPLE MATRIX -------------------------------------------------------------

mat <- sobol_matrices(N = N, params = params, order = order)
mat[, 1] <- floor(qunif(mat[, 1], 3, 100)) # k
mat[, 2] <- floor(qunif(mat[, 2], 10, 1000)) # N_t
mat[, 3] <- round(qunif(mat[, 3], 0.3, 0.5), 2) # k_2
mat[, 4] <- round(qunif(mat[, 4], 0.1, 0.3), 2) # k_3
mat[, 5] <- floor(qunif(mat[, 5], 1, 200)) # Epsilon
mat[, 6] <- floor(mat[, 6] * (8 - 1 + 1)) + 1 # Phi
mat[, 7] <- floor(mat[, 7] * (3 - 1 + 1)) + 1 # Phi

colnames(mat) <- params

N.all <- apply(mat, 1, function(x) ceiling(x["N_t"] / (x["k"] + 1)))
N.azzini <- apply(mat, 1, function(x) ceiling(x["N_t"] / (2 * x["k"] + 2)))

tmp <- cbind(mat, N.all, N.azzini)
sel <- c("N.all", "N.azzini")

mat <- as.matrix(data.table(tmp)[, (sel):= lapply(.SD, function(x) 
  ifelse(x == 1, 2, x)), .SDcols = (sel)])
```

## Define the model

This section codes the model, which works as follows:

\begin{itemize}
\item Create the `estimators` vector, which includes the name of all estimators.
\item Create a (`N.all`, $k$) sample matrix formed by an $\textbf{A}$ and an $\textbf{A}_B^{(i)}$ matrix, which will be used to compute all $T_i$ estimators except the Azzini, which requires an $\textbf{A}$, $\textbf{B}$, $\textbf{A}_B^{(i)}$ and a $\textbf{B}_A^{(i)}$ matrix.
\item Create a (`N.high`, $k$) sample matrix formed by an $\textbf{A}$ and an $\textbf{A}_B^{(i)}$ matrix. This will be the "large" sample matrix used to compute the "true" total-order indices. It will have an $\textbf{A}$ and an $\textbf{A}_B^{(i)}$ matrix because the reference estimator to compute the true total-order indices will be the Jansen estimator.
\item We then bind all three sample matrices and call the metafunction throughout. Binding is mandatory here as the metafunction needs to be called just once: if we call the metafunction in each sample matrix separately, its randomness will make it different each time and the comparison will not be possible.
\item We compute the "true" total-order indices for the "large" sample matrix only using the Jansen estimator.
\item We compute the total-order indices using each estimator. This works with a `for` loop.
\end{itemize}

```{r define_model, cache=TRUE, dependson=c("sample_matrices_functions", "metafunction", "ti_indices", "savage_scores")}

# DEFINE MODEL ---------------------------------------------------------------------

model_Ti <- function(k, N.all, N.azzini, N.high, k_2, k_3, epsilon, phi, delta) {
  ind <- list()
  estimators <- c("jansen", "sobol", "homma", "monod", "azzini")
  all.but.azzini <- sobol_matrices(N = N.all, params = paste("X", 1:k, sep = ""), 
                                   matrices = c("A", "AB"))
  azzini <- sobol_matrices(N = N.azzini, params = paste("X", 1:k, sep = ""), 
                           matrices = c("A", "B", "AB", "BA"))
  large.matrix <- sobol_matrices(N = N.high, params = paste("X", 1:k, sep = ""), 
                                 matrices = c("A", "AB"))
  set.seed(epsilon)
  all.matrices <- random_distributions(X = rbind(all.but.azzini, azzini, large.matrix), 
                                       phi = phi)
  output <- sensobol::metafunction(data = all.matrices, 
                                   k_2 = k_2, 
                                   k_3 = k_3, 
                                   epsilon = epsilon)
  full.ind <- sobol_Ti(d = tail(output, nrow(large.matrix)), 
                       N = N.high, 
                       params = paste("X", 1:k, sep = ""), 
                       total = "jansen")
  full.ind[, sample.size:= "N"]
  for(i in estimators) {
    if(!i == "azzini") {
      y <- output[1:nrow(all.but.azzini)]
      n <- N.all
    } else {
      y <- output[-c(1:nrow(all.but.azzini), 
                     (nrow(all.but.azzini) + nrow(azzini) + 1):length(output))]
      n <- N.azzini
    }
    ind[[i]] <- sobol_Ti(d = y, N = n, params = paste("X", 1:k, sep = ""), total = i)
    ind[[i]][, sample.size:= "n"]
    ind[[i]] <- rbind(ind[[i]], full.ind)
  }
  # Arrange data
  out <- rbindlist(ind, idcol = "estimator") 
  out.wide <- dcast(out, estimator + parameters ~ sample.size, value.var = "Ti")
  if(delta == 1) { # Regular Pear
    final <- out.wide[, .(correlation = cor(N, n)), estimator]
  } else if(delta == 2) { # kendall tau
    final <- out.wide[, .(correlation = pcaPP::cor.fk(N, n)), estimator]
  } else { # Savage ranks
    final <- out.wide[, lapply(.SD, savage_scores), .SDcols = c("N", "n"), estimator][
      , .(correlation = cor(N, n)), estimator]
  }
  return(final)
}
```

## Run the model

This code snippet runs the model. In my computer (see section System Information) it took approximately 4 h.

```{r model_run, cache=TRUE, dependson=c("define_model", "settings", "sample_matrix", "source_cpp")}

# RUN MODEL ------------------------------------------------------------------------

# Define parallel computing
cl <- makeCluster(n_cores)
registerDoParallel(cl)

# Compute
Y.ti <- foreach(i=1:nrow(mat), 
                .packages = c("sensobol", "data.table", "pcaPP", 
                                 "logitnorm")) %dopar%
  {
    model_Ti(k = mat[[i, "k"]], 
             k_2 = mat[[i, "k_2"]], 
             k_3 = mat[[i, "k_3"]],
             epsilon = mat[[i, "epsilon"]],
             phi = mat[[i, "phi"]],
             delta = mat[[i, "delta"]],
             N.all = mat[[i, "N.all"]], 
             N.azzini = mat[[i, "N.azzini"]], 
             N.high = N.high)
  }

# Stop parallel cluster
stopCluster(cl)
```

## Arrange output

This section arranges the output to plot the results.

```{r arrange_output, cache=TRUE, dependson="model_run"}

# ARRANGE OUTPUT -------------------------------------------------------------------

out_cor <- rbindlist(Y.ti, idcol = "row")

mt.dt <- data.table(mat) %>%
  .[, row:= 1:.N]

full_output <- merge(mt.dt, out_cor) %>%
  .[, Nt:= ifelse(estimator == "azzini", N.azzini * (2 * k + 2), N.all * (k + 1))] %>%
  .[, estimator:= ifelse(estimator %in% "azzini", "Azzini and Rosati", 
                        ifelse(estimator %in% "homma", "Homma and Saltelli",
                               ifelse(estimator %in% "monod", "Janon/Monod", 
                                      ifelse(estimator %in% "jansen", "Jansen", "Sobol'"))))] %>%
  .[, ratio:= Nt / k]

# Define A matrix
A <- full_output[,.SD[1:N], estimator]
```

```{r export_output, cache=TRUE, dependson="arrange_output"}

# EXPORT OUTPUT --------------------------------------------------------------------

fwrite(out, "out.csv")
```

```{r plot_full, cache=TRUE, dependson="arrange_output", fig.height=8, fig.width=4}

# PLOT OUTPUT ----------------------------------------------------------------------

# Scatterplot
a <- ggplot(A[correlation > 0], aes(Nt, k, color = correlation)) +
  geom_point(size = 0.3) + 
  scale_colour_gradientn(colours = c("purple", "red", "orange", "lightgreen"), 
                         name = expression(italic(r))) +
  scale_x_continuous(breaks = pretty_breaks(n = 3)) +
  labs(x = expression(italic(N[t])), 
       y = expression(italic(k))) + 
  facet_wrap(~estimator, 
             ncol = 1) + 
  theme_AP() + 
  theme(legend.position = "none")

# Get legend
legend <- get_legend(a + theme(legend.position = "top"))

# Ratio
b <- ggplot(A[correlation > 0], aes(ratio, correlation)) +
  geom_point(alpha = 0.15, size = 0.6) +
  facet_wrap(~estimator, 
             ncol = 1) +
  labs(x = expression(italic(N[t]/k)), 
       y = expression(italic(r))) +
  scale_x_log10() +
  theme_AP()

# Merge plot
bottom <- plot_grid(a, b, ncol = 2, labels = "auto")
plot_grid(legend, bottom, ncol = 1, rel_heights = c(0.15, 1))
```

```{r plot_boxplot, cache=TRUE, dependson="arrange_output", dev = "tikz", fig.width=4, fig.height=3}

# PLOT BOXPLOT ---------------------------------------------------------------------

ggplot(A[correlation > 0], aes(estimator, correlation)) +
  geom_boxplot() + 
  labs(x = "", 
       y = expression(italic(r))) + 
  theme_AP() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

# Sensitivity analysis

```{r sensitivity_analysis, cache=TRUE, dependson=c("arrange_output", "sobol_indices")}

# SENSITIVITY ANALYSIS -------------------------------------------------------------

params.plot <- c("$k$", "$N_t$", "$k_2$", "$k_3$", "$\\varepsilon$", "$\\phi$", 
                 "$\\delta$")

indices <- full_output[, sobol_indices(Y = correlation, 
                                       N = N,
                                       params = params.plot,
                                       first = "jansen",
                                       R = R, 
                                       boot = TRUE, 
                                       order = order), 
                       estimator]
```

```{r plot_sobol_indices, cache=TRUE, dependson=c("sensitivity_analysis", "sobol_indices_f"), fig.height=8, fig.width=2.5, dev = "tikz"}

# PLOT SOBOL' INDICES --------------------------------------------------------------

# Reorder the levels of the parameters
indices <- indices[, parameters:= factor(parameters, 
                                         levels = c("$N_t$", "$k$", "$k_2$", 
                                                    "$k_3$", "$\\varepsilon$", 
                                                    "$\\phi$", "$\\delta$"))]

ggplot(indices, aes(parameters, original, fill = sensitivity)) +
  geom_bar(stat = "identity", 
           position = position_dodge(0.6), 
           color = "black") +
  geom_errorbar(aes(ymin = low.ci, 
                    ymax = high.ci), 
                position = position_dodge(0.6)) +
  facet_wrap(~estimator, 
             ncol = 1) +
  labs(x = "", 
       y = "Sobol' index") +
  scale_fill_discrete(name = "Sobol' indices", 
                      labels = c(expression(S[i]), 
                                 expression(T[i]))) +
  theme_AP() +
  theme(legend.position = "top")
```

```{r sum_si, cache=TRUE, dependson="sensitivity_analysis"}

# SUM OF FIRST-ORDER INDICES -------------------------------------------------------

indices[sensitivity == "Si", sum(original), estimator]
```

\newpage 

# Session information

```{r session_information}

# SESSION INFORMATION ---------------------------------------------------------

sessionInfo()

## Return the machine CPU
cat("Machine:     "); print(get_cpu()$model_name)

## Return number of true cores
cat("Num cores:   "); print(detectCores(logical = FALSE))

## Return number of threads
cat("Num threads: "); print(detectCores(logical = TRUE))

## Return the machine RAM
cat("RAM:         "); print (get_ram()); cat("\n")
```

\newpage

# References